# DPR-LLM-typescript: Design Pattern Retrieval & Embeddings Analysis

Este proyecto tiene como objetivo construir un dataset de "Ground Truth" de implementaciones de patrones de dise√±o (GoF) en **TypeScript**, extray√©ndolos de repositorios reales de GitHub. Posteriormente, utiliza modelos de lenguaje locales (via Ollama) para generar embeddings de estos fragmentos de c√≥digo, permitiendo tareas de an√°lisis, b√∫squeda sem√°ntica o clasificaci√≥n.

## üöÄ Flujo de Trabajo

El proyecto consta de tres etapas principales:

### 1. Miner√≠a de Datos (`mining_repo.py`)
- **B√∫squeda:** Utiliza la API de GitHub para encontrar repositorios de TypeScript etiquetados con temas como `design-patterns`, `software-architecture`, etc.
- **Filtrado:** Descarta repositorios con pocas estrellas (< 15) para asegurar una calidad m√≠nima.
- **Extracci√≥n:** Clona temporalmente los repositorios y busca carpetas que coincidan con los nombres de los 23 patrones de dise√±o GoF (ej. `Singleton`, `Factory`, `Strategy`).
- **Organizaci√≥n:** Copia los archivos `.ts` encontrados a la carpeta `dataset_ground_truth/`, organizados por patr√≥n y renombrados para mantener la trazabilidad del origen (`RepoName__FileName.ts`).

### 2. Generaci√≥n de Embeddings (`generate_embeddings.py`)
- **Preprocesamiento:** Limpia el c√≥digo TypeScript extra√≠do (elimina comentarios, reduce espacios, trunca a un l√≠mite seguro de tokens).
- **Inferencia Local:** Utiliza **Ollama** para generar embeddings vectoriales del c√≥digo utilizando m√∫ltiples modelos:
  - `nomic-embed-text`
  - `qwen2.5-coder`
  - `llama3.2`
- **Persistencia:** Guarda los embeddings y metadatos resultantes en `embeddings_dataset.json`.

### 3. An√°lisis (`analysis.ipynb`)
- Cuaderno Jupyter (previsto) para explorar, visualizar (t-SNE/PCA) o evaluar la calidad de los embeddings generados.

## üõ†Ô∏è Requisitos Previos

- **Python 3.10+**
- **Ollama**: Debe estar instalado y ejecut√°ndose localmente (`ollama serve`).
- **Modelos Ollama**: Debes tener descargados los modelos utilizados:
  ```bash
  ollama pull nomic-embed-text
  ollama pull qwen2.5-coder:7b
  ollama pull llama3.2
  ```
- **GitHub Token**: Necesario para el script de miner√≠a.

## üì¶ Instalaci√≥n

1. Clona este repositorio.
2. Instala las dependencias (usar UV de preferencia):
   ```bash
   pip install -r requirements.txt
   # O si usas poetry/otro gestor, revisa pyproject.toml
   ```
3. Configura tu token de GitHub en un archivo `.env`:
   ```env
   GITHUB_TOKEN=ghp_tu_token_secreto_aqui
   ```

## ‚ñ∂Ô∏è Uso

1. **Generar el Dataset:**
   Ejecuta el minero para buscar y descargar c√≥digo.
   ```bash
   python mining_repo.py
   ```
   *Esto crear√° la carpeta `dataset_ground_truth/`.*

2. **Generar Embeddings:**
   Procesa el dataset con Ollama.
   ```bash
   python generate_embeddings.py
   ```
   *Esto generar√° el archivo `embeddings_dataset.json`.*

## üìÇ Estructura de Carpetas

```
.
‚îú‚îÄ‚îÄ dataset_ground_truth/       # Dataset generado (C√≥digo fuente limpio)
‚îÇ   ‚îú‚îÄ‚îÄ AbstractFactory/
‚îÇ   ‚îú‚îÄ‚îÄ Singleton/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo-a__Instance.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ embeddings_dataset.json     # Resultado final con vectores
‚îú‚îÄ‚îÄ generate_embeddings.py      # Script de generaci√≥n de embeddings
‚îú‚îÄ‚îÄ mining_repo.py              # Script de miner√≠a de GitHub
‚îú‚îÄ‚îÄ analysis.ipynb              # Notebook de an√°lisis
```
